# UNED Master en Investigación en Inteligencia Artificial



- [UNED Master en Investigación en Inteligencia Artificial](#uned-master-en-investigación-en-inteligencia-artificial)
  - [Objetivos  ↑ Volver al inicio](#objetivos)
  - [Estructura del Máster  ↑ Volver al inicio](#estructura-del-máster)
  - [Inicio Rápido  ↑ Volver al inicio](#inicio-rápido)
- [Guía de estudio de las asignaturas del Máster en IA (UNED)](#guía-de-estudio-de-las-asignaturas-del-máster-en-ia-uned)
  - [Aprendizaje Profundo (Deep Learning)   ↑ Volver al inicio](#aprendizaje-profundo-deep-learning-)
  - [Fundamentos del Procesamiento Lingüístico (Procesamiento de Lenguaje Natural)  ↑ Volver al inicio](#fundamentos-del-procesamiento-lingüístico-procesamiento-de-lenguaje-natural)
  - [Minería de Datos (Data Mining)  ↑ Volver al inicio](#minería-de-datos-data-mining)
  - [Sistemas Adaptativos en Educación  ↑ Volver al inicio](#sistemas-adaptativos-en-educación)
  - [Métodos Simbólicos  ↑ Volver al inicio](#métodos-simbólicos)
  - [Métodos Probabilistas  ↑ Volver al inicio](#métodos-probabilistas)
  - [Computación Evolutiva  ↑ Volver al inicio](#computación-evolutiva)
  - [Visión Artificial (Computer Vision)  ↑ Volver al inicio](#visión-artificial-computer-vision)
  - [Descubrimiento de Información en Textos (Text Mining)  ↑ Volver al inicio](#descubrimiento-de-información-en-textos-text-mining)
  - [Aplicaciones de la Inteligencia Artificial para el Desarrollo Humano y Sostenible  ↑ Volver al inicio](#aplicaciones-de-la-inteligencia-artificial-para-el-desarrollo-humano-y-sostenible)
  - [Web Semántica y Enlazado de Datos (Semantic Web \& Linked Data)  ↑ Volver al inicio](#web-semántica-y-enlazado-de-datos-semantic-web--linked-data)
  - [Métodos de Aprendizaje Automático (Machine Learning)  ↑ Volver al inicio](#métodos-de-aprendizaje-automático-machine-learning)
  - [Trabajo de Fin de Máster en Investigación en IA  ↑ Volver al inicio](#trabajo-de-fin-de-máster-en-investigación-en-ia)
  - [Metodología de Investigación en Sistemas Inteligentes  ↑ Volver al inicio](#metodología-de-investigación-en-sistemas-inteligentes)
  - [Autor  ↑ Volver al inicio](#autor)
  - [Licencia  ↑ Volver al inicio](#licencia)
 

</details>


Repositorio con materiales, códigos y recursos del **Máster Universitario en Investigación en Inteligencia Artificial** de la **UNED** (Universidad Nacional de Educación a Distancia).

## Objetivos <a id="objetivos"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

- **Centralizar** todos los recursos académicos y prácticos
- **Implementar** algoritmos y técnicas de IA desde cero
- **Documentar** experiencias y aprendizajes
- **Construir** un portafolio en IA

## Estructura del Máster <a id="estructura-del-máster"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

| Código     | Nombre Asignatura                                               | Créditos | Descripción Breve                                                                                   |
|------------|----------------------------------------------------------------|----------|---------------------------------------------------------------------------------------------------|
| 31080010   | Aprendizaje Profundo                                           | 6        | Técnicas avanzadas de redes neuronales profundas.                                                  |
| 31080027   | Fundamentos del Procesamiento Lingüístico                      | 6        | Bases para el análisis y comprensión del lenguaje natural.                                        |
| 31101061   | Minería de Datos                                               | 6        | Métodos para extraer conocimiento de grandes datos.                                               |
| 31101095   | Sistemas Adaptativos en Educación                              | 6        | Sistemas que se ajustan automáticamente para optimizar el aprendizaje.                            |
| 3110117-   | Métodos Simbólicos                                             | 6        | Técnicas basadas en lógica y representaciones simbólicas.                                         |
| 31101199   | Métodos Probabilistas                                          | 6        | Modelos probabilísticos aplicados a la IA.                                                        |
| 31101220   | Computación Evolutiva                                          | 6        | Algoritmos inspirados en evolución biológica.                                                    |
| 31101235   | Visión Artificial                                             | 6        | Procesamiento e interpretación de imágenes y vídeo.                                              |
| 31101254   | Descubrimiento de Información en Textos                       | 6        | Técnicas para extracción de información relevante de textos.                                     |
| 31101273   | Aplicaciones de la Inteligencia Artificial para el Desarrollo Humano y Sostenible | 6 | Uso de IA para soluciones sostenibles y sociales.                                                |
| 31108018   | Web Semántica y Enlazado de Datos                             | 6        | Tecnologías para enlazar y dar sentido a datos en la web.                                        |
| 31108037   | Métodos de Aprendizaje Automático                             | 6        | Técnicas clásicas y modernas de aprendizaje supervisado y no supervisado.                        |
| 31108022   | Trabajo de Fin de Máster en Investigación en Inteligencia Artificial | 27   | Proyecto integrador de investigación avanzada en IA.                                            |
| 31108041   | Metodología de Investigación en Sistemas Inteligentes         | 3        | Técnicas y métodos para investigación en IA.                                                    |

## Inicio Rápido <a id="inicio-rápido"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

```bash
# Clonar el repositorio
git clone https://github.com/fmmarco29/UNED_AI_lab.git

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar Jupyter Lab
jupyter lab
```

# Guía de estudio de las asignaturas del Máster en IA (UNED)

A continuación se describen detalladamente cada una de las asignaturas del **Máster Universitario en Investigación en Inteligencia Artificial** de la UNED, analizando su contenido, valor académico y profesional, ejemplos de aplicaciones prácticas y recursos recomendados.

## Aprendizaje Profundo (Deep Learning)&#x20; <a id="aprendizaje-profundo-deep-learningx20"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** Esta asignatura introduce los fundamentos de las **redes neuronales profundas**. Se estudian modelos de aprendizaje automáticos basados en **capas ocultas** (hidden layers) que permiten procesar información compleja (imágenes, voz, texto) con alto nivel de precisión. Aunque las redes neuronales profundas no son una tecnología nueva, la disponibilidad de recursos de cómputo masivo (GPUs, clústeres) ha permitido implementarlas con gran eficacia. La asignatura abarca los principios teóricos (perceptrón, retropropagación) y las principales arquitecturas modernas, así como las herramientas (por ejemplo, bibliotecas de código abierto) para diseñar y entrenar modelos de Deep Learning.

**Valor académico/profesional:** El aprendizaje profundo se considera hoy uno de los campos más revolucionarios de la inteligencia artificial. De hecho, muchos de los avances recientes en IA (como coches autónomos, asistentes virtuales, generación de texto e imágenes) surgen de aplicar redes neuronales profundas. Estos métodos superan a las técnicas tradicionales de aprendizaje automático en tareas complejas de reconocimiento de patrones y son ampliamente utilizados en la industria y la investigación. Por ejemplo, Google destaca que el Deep Learning es clave para tareas como reconocimiento de imágenes y de voz, procesamiento del lenguaje natural y traducción automática. La asignatura prepara al estudiante para aplicar Deep Learning en ámbitos de alto impacto (automoción, medicina, finanzas, etc.), donde se logran soluciones con precisión muy alta en visión por computador o reconocimiento del habla.

**Aplicaciones prácticas:** Entre las aplicaciones destacadas del Deep Learning se incluyen:

* **Visión por computador:** reconocimiento de objetos, detección de anomalías o fallos en imágenes de fabricación, diagnóstico médico por imagen, sistemas avanzados de asistencia al conductor (ADAS) en vehículos autónomos.
* **Procesamiento de voz y lenguaje:** asistentes personales inteligentes (Alexa, Siri) que comprenden instrucciones por voz, traducción automática de idiomas, chatbots de atención al cliente. Las redes neuronales recurrentes y transformadores mejoran las traducciones y el reconocimiento de voz.
* **Sistemas de recomendación y marketing:** modelos basados en Deep Learning analizan grandes volúmenes de datos de usuarios para recomendar productos o contenidos personalizados.
* **Industria 4.0 y robótica:** en la automatización industrial, modelos de Deep Learning controlan procesos adaptativos y mantenimiento predictivo.

**Recursos recomendados:** Para superar esta asignatura se sugiere practicar con entornos de Python y bibliotecas de Deep Learning como **TensorFlow**, **PyTorch** y **Keras**. Bibliografía clave incluye *“Deep Learning”* de Goodfellow et al. y *“Deep Learning with Python”* de François Chollet. También son útiles cursos en línea (por ejemplo, el curso de Deep Learning de Andrew Ng en Coursera) y proyectos en repositorios públicos (GitHub) sobre redes neuronales convolucionales o redes generativas. Se recomienda además familiarizarse con recursos adicionales en inglés, dada la novedad de muchos contenidos, y utilizar software de código abierto cuando sea posible.

## Fundamentos del Procesamiento Lingüístico (Procesamiento de Lenguaje Natural) <a id="fundamentos-del-procesamiento-lingüístico-procesamiento-de-lenguaje-natural"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** Esta asignatura aborda los **métodos básicos de PLN** orientados al análisis automático del lenguaje. Se centra en el estudio de análisis morfológico, sintáctico y semántico de textos, así como en la modelización del conocimiento lingüístico para que las máquinas entiendan y generen lenguaje humano. Es una asignatura teórico-práctica que introduce técnicas de lingüística computacional y reglas basadas en modelos estadísticos para procesar texto. El objetivo es que el alumno sepa usar herramientas de PLN para tareas de análisis textual (tokenización, etiquetado gramatical, análisis sintáctico, extracción de significado).

**Valor académico/profesional:** El PLN es fundamental en la actualidad porque conecta el mundo humano con la inteligencia artificial: permite que los ordenadores comprendan y generen texto y voz en lenguaje natural. Hoy en día el PLN impulsa muchas aplicaciones de la vida diaria. IBM destaca que sistemas de búsqueda, asistentes virtuales (Alexa, Siri, Cortana) y chatbots de servicio al cliente operan gracias a técnicas de PLN. Además, los modelos de lenguaje avanzados (como GPT-4) basados en PLN están marcando la era de la IA generativa. Profesionalmente, el conocimiento en PLN es muy valorado en áreas de análisis de texto (minería de opiniones, análisis de sentimiento) y en industrias que manejan gran volumen de información (búsqueda en empresas, análisis de redes sociales, legaltech, salud, finanzas).

**Aplicaciones prácticas:** Ejemplos de aplicación del PLN incluyen:

* **Asistentes de voz y chatbots:** como asistentes virtuales que responden preguntas de clientes, basados en reconocimiento de voz y generación de lenguaje natural.
* **Traducción automática:** sistemas que convierten texto o voz de un idioma a otro conservando significado y contexto.
* **Análisis de documentos y minería de texto:** extracción de información clave de documentos legales o médicos, clasificación automática de correos electrónicos (spam), análisis de sentimientos en redes sociales.
* **Mejora de búsquedas:** motores de búsqueda que entienden la intención de la consulta y devuelven resultados más precisos usando modelos semánticos.
* **Generación de contenido:** herramientas que redactan automáticamente textos de marketing, resúmenes o informes a partir de datos, utilizando modelos de PLN.

**Recursos recomendados:** Se aconseja practicar con bibliotecas de PLN como **NLTK**, **spaCy**, **Gensim** o **HuggingFace Transformers**. Para profundizar, son útiles el libro *“Speech and Language Processing”* de Jurafsky y Martin y el curso *“Natural Language Processing”* de Stanford (disponible en línea). También conviene usar repositorios de datos y *corpora* etiquetados (Wikipedia, proyectos CLARIN, etc.) y participar en cursos de especialización (por ejemplo de Coursera o edX) sobre PLN y aprendizaje de máquinas aplicadas al texto.

## Minería de Datos (Data Mining) <a id="minería-de-datos-data-mining"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** Esta asignatura ofrece una visión amplia de los **conceptos y técnicas de minería de datos**. Cubre las principales tareas (descubrimiento de patrones, clasificación, agrupamiento, evaluación de modelos) y las herramientas más habituales para resolverlas. Se estudia el proceso completo de extracción de conocimiento: limpieza de datos, selección de características, aplicación de algoritmos de minería (árboles de decisión, redes neuronales, clustering, reglas de asociación, etc.) y evaluación de resultados. El enfoque es práctico: se trata cada técnica como un componente reutilizable que se elige según el problema (según la asignatura, “como una librería de componentes seleccionables”).

**Valor académico/profesional:** La minería de datos es un pilar central de la ciencia de datos. Según la UNED, está “en el núcleo de las atribuciones” necesarias hoy día en Data Science y cualquier profesional del área debe dominar sus conceptos y herramientas. Permite extraer conocimiento útil de grandes volúmenes de datos, una habilidad clave en casi todas las industrias. Se emplea masivamente en sectores que necesitan analizar datos históricos o de clientes para tomar decisiones informadas. En la industria eléctrica, por ejemplo, la minería de datos se utiliza en redes inteligentes (smart grids) para predecir consumos y optimizar recursos. Asimismo, en banca y finanzas se usa para **calificación crediticia** y **detección de fraude**, analizando transacciones con algoritmos de clasificación. En marketing se emplea para **segmentación de clientes** y diseñar campañas personalizadas. En el comercio minorista (retail) se aplican técnicas de asociación (como las reglas “carrito de la compra”) para optimizar estanterías y ofertas. En sanidad permite mejorar diagnósticos y eficiencias gestionando historiales de pacientes.

**Aplicaciones prácticas:** Algunos ejemplos destacados son:

* **Banca y finanzas:** calificación de riesgos crediticios y sistemas antifraude que analizan enormes volúmenes de operaciones para detectar comportamientos anómalos.
* **Marketing y retail:** minería de datos para segmentar mercados, predecir abandono de clientes (churn) o analizar hábitos de compra, optimizando estrategias de fidelización.
* **Agricultura inteligente:** uso de datos climáticos y del suelo para predecir rendimientos de cultivos y optimizar siembras.
* **Medicina:** extraer patrones de datos clínicos para diagnósticos más precisos, gestión de recursos sanitarios o predicción de enfermedades en la población.

**Recursos recomendados:** Para esta materia conviene dominar lenguajes como Python (bibliotecas **Pandas**, **Scikit-Learn**, **NumPy**) o R. Herramientas como **Weka**, **KNIME** u **Orange** facilitan experimentar con algoritmos de minería. Libros clásicos son *“Data Mining: Concepts and Techniques”* de Han, *“Pattern Recognition and Machine Learning”* de Bishop o *“Aprendizaje automático”* de Alpaydın. Existen numerosos cursos en línea (por ejemplo en DataCamp, edX o Udemy) sobre técnicas de minería de datos y análisis de datos. También se recomiendan practicar con repositorios de datos públicos (datasets de Kaggle o UCI) para implementar proyectos de minería.

## Sistemas Adaptativos en Educación <a id="sistemas-adaptativos-en-educación"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** La asignatura se centra en el desarrollo de **sistemas adaptativos educativos**. Estos son sistemas inteligentes que ajustan dinámicamente el contenido y la metodología de enseñanza según el alumno. Se estudian los fundamentos metodológicos y tecnológicos para diseñar estas plataformas, incluyendo técnicas de *Learning Analytics* y *Minería de Datos Educativa* (Educational Data Mining) que modelan el proceso de aprendizaje y perfilan al estudiante. En la práctica, el alumno investiga cómo funcionan estos sistemas y realiza experiencias prácticas aplicando conocimientos de otras materias (como minería de datos o aprendizaje automático) al contexto educativo. La asignatura también aborda aspectos éticos y de privacidad en entornos de e-learning. Se trabaja preferentemente en Python (se ofrece apoyo si no se domina) y se considera fundamental entender idiomas y programación.

**Valor académico/profesional:** Los sistemas adaptativos en educación son un área emergente con gran proyección en el ámbito educativo y tecnológico. Con la expansión de la educación en línea (MOOCs, e-learning corporativo, plataformas de formación continua), crece la necesidad de personalizar el aprendizaje. Este campo integra IA, pedagogía y tecnología para crear tutorías inteligentes, aprendizaje personalizado y sistemas de recomendación pedagógica. Aprender sobre ellos prepara al estudiante para roles en el sector educativo, en empresas de tecnología educativa (*edtech*) o en investigación en educación asistida por IA. Además, comprende la gestión ética y de diversidad de estos sistemas, un aspecto cada vez más relevante en cualquier aplicación tecnológica educativa.

**Aplicaciones prácticas:** Entre las aplicaciones más directas destacan los sistemas de tutoría inteligente y plataformas adaptativas, como:

* **Plataformas e-learning adaptativas:** entornos (por ejemplo, Khan Academy, Moodle con plugins adaptativos o edX) que ajustan ejercicios y recursos según el rendimiento del alumno.
* **Sistemas de recomendación de contenidos:** recomendar actividades, vídeos o lecturas específicas basándose en el perfil y progreso de cada estudiante.
* **Análisis de aprendizaje (Learning Analytics):** dashboards y analítica que rastrean la interacción del alumno (tiempos de estudio, resultados de tests) para anticipar dificultades y optimizar la enseñanza. Por ejemplo, identificar estudiantes en riesgo de abandono y ofrecerles material adicional.
* **Tutorías virtuales inteligentes:** chatbots educativos que guían al alumno según su nivel de comprensión.

**Recursos recomendados:** Se aconseja familiarizarse con marcos de trabajo de e-learning y análisis de datos educativos. Por ejemplo, **Moodle** (con herramientas de analítica educativa) y **Jupyter/Python** para procesar logs de aprendizaje. Libros como *“Artificial Intelligence in Education”* (Ian Levine et al.) o artículos sobre Educational Data Mining ofrecen bases teóricas. Cursos en línea sobre “Data Science en educación” o “Learning Analytics” pueden complementar. Repositorios de investigaciones (journals de tecnología educativa) son útiles para conocer casos de estudio reales.

## Métodos Simbólicos <a id="métodos-simbólicos"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** Esta asignatura aborda los **métodos simbólicos** de la IA, centrados en el conocimiento **explícito**. Se estudian las representaciones de conocimiento (lógicas y semánticas) para sistemas de IA, como ontologías, lógica de predicados, razonamiento basado en reglas y argumentación. El alumno aprende a modelar dominios con símbolos (conceptos, relaciones) y a implementar sistemas basados en reglas lógicas (por ejemplo, motores de inferencia). Se incluyen temas como el tratamiento simbólico del lenguaje (ontologías del lenguaje) y su aplicación en sistemas inteligentes. Se enfatiza el **pensamiento lógico** y la estructuración de conocimiento, en contraste con los enfoques de aprendizaje automático.

**Valor académico/profesional:** Los métodos simbólicos conforman la tradición histórica de la IA (“IA basada en conocimiento”). Aunque hoy coexisten con métodos de aprendizaje profundo, siguen siendo esenciales para aplicaciones que requieren interpretabilidad y razonamiento explícito. Por ejemplo, se usan en **sistemas expertos** (médicos, legales, financieros) donde las reglas deben ser transparentes. También son la base de la Web Semántica y la gestión de grafos de conocimiento (Knowledge Graphs). En la industria, las IA simbólicas permiten construir sistemas explicables, verificar reglas de negocio complejas o integrar múltiples fuentes de datos mediante modelos ontológicos. Aprender estos métodos dota al estudiante de herramientas para resolver problemas donde el conocimiento previo es crítico y para construir IA con capacidad de razonamiento simbólico (lógica difusa, sistemas basados en lógica, agentes inteligentes).

**Aplicaciones prácticas:** Ejemplos de uso de la IA simbólica incluyen:

* **Sistemas expertos y decisiones basadas en reglas:** como sistemas de apoyo a la decisión en medicina o finanzas, donde se encadenan reglas lógicas para diagnosticar o evaluar riesgos.
* **Ontologías y modelos de conocimiento:** construcción de ontologías (p.ej. en salud o bibliotecas digitales) para unificar información y permitir consultas semánticas.
* **Web Semántica y bases de conocimiento:** motores de inferencia que responden a preguntas complejas usando bases de triples RDF.
* **Lenguajes de programación lógica:** aplicaciones de Prolog en inteligencia artificial clásica, robótica o juegos (resolución de puzzles mediante búsqueda lógica).

**Recursos recomendados:** Es útil practicar con herramientas como **Protégé** para crear ontologías OWL/RDF y con motores de reglas (por ejemplo **Drools** o **Jess**). Para lógica computacional, lenguajes como **Prolog** (SWI-Prolog) o sistemas simbólicos (Mathematica) son relevantes. Entre los libros destacan *“Artificial Intelligence: A Modern Approach”* (Russell & Norvig), que aborda métodos simbólicos, y *“Knowledge Representation and Reasoning”* (Brachman & Levesque). Cursos sobre lógica computacional o Web Semántica (muchos en línea) pueden complementar. Además, explorar repositorios de proyectos de ontologías (DBpedia, Wikidata) ayuda a entender implementaciones reales.

## Métodos Probabilistas <a id="métodos-probabilistas"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** Esta asignatura estudia los **modelos probabilísticos** en IA. Se introduce la base matemática necesaria (cálculo de probabilidades, estadística) y los **modelos gráficos probabilistas** (redes bayesianas, diagramas de influencia, modelos de Markov) como herramientas para razonar bajo incertidumbre. El marco probabilista combina informática, estadística y aprendizaje automático para representar problemas con información incierta. Se enseñan algoritmos de inferencia y aprendizaje en estos modelos (p. ej. propagación de evidencias en una red Bayesiana). El curso incluye software especializado para construir y resolver modelos probabilistas en aplicaciones reales.

**Valor académico/profesional:** Los métodos probabilistas son esenciales para enfrentar la incertidumbre inherente a muchos problemas reales. Según la UNED, constituyen la base de aplicaciones como diagnóstico médico, percepción en visión artificial, robótica o PLN. Son clave en cualquier sistema que deba **tomar decisiones con datos inciertos**. Por ejemplo, en medicina se usan redes bayesianas para diagnosticar enfermedades a partir de síntomas incompletos; en robótica para localizar un robot dadas lecturas imprecisas de sensores; en PLN para modelos de lenguaje (cadena de Markov, modelos ocultos). Además, dominarlos permite al estudiante aplicar técnicas que combinan probabilidad con otras áreas (por ejemplo, mezclas con modelos evolutivos o lógicos). Profesionalmente, el saber construir y aplicar estos modelos capacita para roles en sectores de riesgo (seguros, medicina) y procesamiento de señales o datos con ruido.

**Aplicaciones prácticas:** Algunos casos prácticos son:

* **Diagnóstico médico:** usar redes bayesianas para combinar probabilidades de síntomas y enfermedades, ayudando a médicos en diagnósticos complejos.
* **Sistemas de navegación robótica:** algoritmos probabilistas (filtros de Kalman o partículas) permiten al robot estimar su posición con sensores imprecisos.
* **Reconocimiento de voz e imagen:** modelos como cadenas de Markov ocultas (HMM) son la base de tecnologías de reconocimiento de voz o análisis de imágenes bajo ruido.
* **Predicción financiera o de riesgos:** se emplean modelos probabilistas para evaluar incertidumbres en mercados o clasificar transacciones (como parte de sistemas de detección de fraude).

**Recursos recomendados:** Para practicar se pueden usar bibliotecas como **pgmpy** o **pomegranate** en Python, o herramientas de pago como **Hugin** o **Netica** para redes bayesianas. En cuanto a literatura, *“Probabilistic Graphical Models”* de Koller & Friedman es una referencia, así como cursos de estadística aplicada a IA. También es útil el curso “Probabilistic Reasoning” en plataformas como Coursera, y repositorios de datasets para construir modelos (por ejemplo, UCI Machine Learning Repository para datos clínicos).

## Computación Evolutiva <a id="computación-evolutiva"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** Esta asignatura ofrece una **introducción exhaustiva a la computación evolutiva**. Se estudian los principales algoritmos inspirados en la evolución natural: algoritmos genéticos, estrategias evolutivas, programación genética, evolución diferencial, sistemas meméticos, etc.. El curso explica cómo estos métodos imitan procesos biológicos (selección natural, mutación) para resolver automáticamente problemas de optimización. El alumno aprende a implementar estos algoritmos para tareas como optimización de funciones, búsqueda de soluciones y generación de estructuras, y se analizan ejemplos prácticos de su uso.

**Valor académico/profesional:** Los métodos evolutivos proporcionan estrategias flexibles para la resolución de problemas difíciles. Son especialmente útiles en optimización y diseño, donde los métodos clásicos fracasan. Según la UNED, pueden verse como una opción adicional para resolver tareas en inteligencia artificial y están relacionados con casi todas las demás áreas del máster. Académicamente, ofrecen un campo de investigación activo (algoritmos híbridos, coevolución). Profesionalmente, se aplican en ingeniería (diseño de componentes, tuning de parámetros), en planificación (p. ej. rutas de drones optimizadas evolutivamente) y en ciencia de datos (búsqueda de óptimos globales). Aprender computación evolutiva dota al estudiante de técnicas versátiles para cuando se necesita búsqueda en espacios muy grandes o adaptabilidad.

**Aplicaciones prácticas:** Ejemplos típicos de aplicación son:

* **Optimización de ingeniería:** diseño de antenas, estructuras o circuitos, donde un algoritmo genético explora múltiples configuraciones y selecciona la más eficiente.
* **Planificación y control:** generar horarios, rutas logísticas o configuraciones de robótica que cumplan múltiples restricciones (por ejemplo, software de planificación de vuelos).
* **Generación automática de programas o arte:** con programación genética se pueden generar modelos o expresiones matemáticas que resuelvan un problema dado.
* **Resolución de problemas combinatorios:** como el viajante de comercio (TSP) o la optimización de procesos industriales usando algoritmos evolutivos.

**Recursos recomendados:** Se recomienda practicar con bibliotecas como **DEAP**, **PyGAD** o **jMetal (Java)** para crear algoritmos evolutivos. El libro *“Fundamentos de Computación Evolutiva”* (Back et al.) es una buena referencia. También existen cursos y tutoriales en línea sobre “Genetic Algorithms” que ayudan a interiorizar la implementación. Para experimentación, utilizar entornos de simulación o datasets de optimización (por ejemplo, conjuntos de pruebas de funciones de optimización) es muy útil.

## Visión Artificial (Computer Vision) <a id="visión-artificial-computer-vision"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** Esta asignatura se dedica a la **visión por computador**. Su objetivo es extraer información a partir de imágenes y datos visuales. Se considera parte del área de percepción de la IA. Se estudian todos los componentes de un sistema de visión completo: adquisición de imagen, preprocesamiento, segmentación, descripción de características, reconocimiento de objetos, reconstrucción 3D, etc. Se enfatiza la necesidad de inyectar conocimiento en cada etapa del procesamiento. La asignatura es aplicada y recoge métodos vistos en otras áreas (simbólicos, automáticos, deep learning) para resolver problemas de imagen; por ejemplo, se estudian filtros de imagen, transformadas (Fourier, Wavelets), y técnicas avanzadas como redes neuronales convolucionales.

**Valor académico/profesional:** La visión artificial es hoy un campo de gran auge tanto en investigación como en industria. Se aplica en robótica autónoma, sistemas de vigilancia, diagnóstico médico por imagen, inspección industrial, realidad aumentada y muchos más. Académicamente, abarca problemas complejos de procesamiento de señales y aprendizaje (visión estéreo, segmentación semántica, etc.) y requiere conocimientos de álgebra y programación. En el ámbito profesional, las habilidades en visión artificial son muy demandadas: empresas tecnológicas y automotrices necesitan ingenieros que desarrollen sistemas de reconocimiento visual (por ejemplo, cámaras inteligentes en fábricas o visión en vehículos autónomos). La asignatura contribuye a que el estudiante domine competencias de procesamiento de imágenes que son esenciales para el ingeniero informático en la era de IA.

**Aplicaciones prácticas:** Entre las aplicaciones más conocidas se cuentan:

* **Vehículos autónomos:** detección y clasificación de peatones, señales de tráfico y obstáculos en tiempo real mediante visión por computador.
* **Inspección industrial:** sistemas que analizan imágenes de productos para detectar defectos de fabricación o medir calidad.
* **Medicina:** análisis automatizado de radiografías, resonancias o imágenes microscópicas para ayudar en el diagnóstico (detección de tumores, retinopatías, etc.).
* **Seguridad y vigilancia:** reconocimiento facial y de acciones en vídeo para sistemas de seguridad.
* **Realidad aumentada/virtual:** seguimiento de marcadores y reconstrucción de escenas para superponer información digital en el mundo real.

**Recursos recomendados:** El uso de bibliotecas especializadas es fundamental: **OpenCV** (biblioteca de visión por computador), **TensorFlow/Keras** o **PyTorch** (para implementar CNNs). Para matemática, libros como *“Computer Vision: Algorithms and Applications”* (Szeliski) son de referencia. Cursos en línea (por ejemplo, “Intro to Computer Vision” de Udacity) pueden ayudar. Igualmente, es útil explorar repositorios de ejemplos (GitHub) de proyectos con visión artificial (detección de objetos con YOLO, segmentación semántica con DeepLab, etc.). Practicar con datasets públicos (COCO, ImageNet) refuerza la experiencia práctica.

## Descubrimiento de Información en Textos (Text Mining) <a id="descubrimiento-de-información-en-textos-text-mining"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** Esta asignatura trata técnicas de PLN específicamente aplicadas a **documentos textuales** extensos. El objetivo es **analizar, caracterizar y extraer información relevante de textos** mediante herramientas automatizadas. Se cubren técnicas clásicas de análisis de texto (por ejemplo, extracción de palabras clave, TF-IDF) y modernas basadas en aprendizaje automático y profundo (vectores de palabras, embeddings, redes neuronales para texto). Además, se estudian tareas de clasificación automática de documentos y agrupamiento (clustering) para organizar grandes colecciones de texto. En definitiva, combina conocimientos de PLN y minería de datos para manejar información textual no estructurada.

**Valor académico/profesional:** El tratamiento de grandes volúmenes de texto es crítico en muchos campos. Esta asignatura desarrolla competencias clave para **gestionar datos textuales masivos**. Por ejemplo, en empresas de consultoría o jurídicas se necesitan técnicas que extraigan datos específicos de informes largos; en inteligencia de negocio, se requiere resumir noticias o informes para obtener insights. El texto libre constituye una gran parte de los datos generados hoy (redes sociales, documentación corporativa), por lo que los conocimientos de text mining tienen gran demanda. En investigación, se usa para minería de opiniones, análisis de sentimientos o sistemas de respuesta a preguntas.

**Aplicaciones prácticas:** Algunos usos frecuentes son:

* **Minería de opiniones (opinion mining):** analizar opiniones de usuarios en redes sociales o encuestas para conocer tendencias de mercado.
* **Sistemas de recomendación basados en texto:** recomendar artículos o documentos relacionados según el contenido textual.
* **Análisis de redes sociales:** estudiar temas emergentes o sentimientos en Twitter, Facebook, etc.
* **Extracción de información en dominios especializados:** por ejemplo, extraer entidades (nombres de genes, medicamentos) de artículos médicos o buscar jurisprudencia relevante en documentos legales.
* **Clasificación y clúster de documentos:** organizar grandes archivos de textos (noticias, historiales médicos) en categorías automáticas, lo que facilita la búsqueda de información.

**Recursos recomendados:** Se aconseja usar herramientas de PLN y minería de texto, como **NLTK**, **spaCy**, **scikit-learn** para clasificación, o **gensim** para modelado de temas. También **elasticSearch** o **Apache Lucene** para indexación y búsqueda en texto. En cuanto a bibliografía, el libro *“Speech and Language Processing”* (Jurafsky & Martin) incluye secciones relevantes. En el plano práctico, existen cursos sobre text mining en plataformas como DataCamp o edX. Bases de datos públicas de texto (Wikipedia, corpus jurídicos o biomédicos) sirven para hacer prácticas reales.

## Aplicaciones de la Inteligencia Artificial para el Desarrollo Humano y Sostenible <a id="aplicaciones-de-la-inteligencia-artificial-para-el-desarrollo-humano-y-sostenible"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** Esta asignatura aborda la **visión social y ética de la IA**. Estudia cómo las tecnologías de IA pueden contribuir al desarrollo humano y sostenible (por ejemplo, en salud, medio ambiente, educación) y analiza normativas y recomendaciones para un uso responsable. Se revisan principios éticos de la IA, su relación con los Objetivos de Desarrollo Sostenible de la ONU, y casos de aplicación humanitaria. Es interdisciplinar, considerando impactos sociales, políticas de privacidad y responsabilidad. Se fomentan debates críticos y proyectos donde el alumno valora cómo la IA beneficia o afecta a las personas, con enfoque en *IA para el bien común*.

**Valor académico/profesional:** Con la creciente adopción de IA en todos los ámbitos, es crucial que los profesionales comprendan sus implicaciones éticas y sociales. Esta materia forma al alumno para ser consciente de los posibles sesgos, brechas o impactos negativos de la IA, y para alinearla con metas de sostenibilidad. Académicamente, prepara al estudiante para investigar líneas como *Fair AI* o *Governance of AI*. Profesionalmente, el conocimiento en IA ética y en aplicaciones para la sostenibilidad (por ejemplo, análisis de datos para recursos hídricos o energía) es muy valorado en sectores público y ONG, donde se busca cumplir con regulaciones (GDPR, directrices europeas) y contribuir a los ODS.

**Aplicaciones prácticas:** Ejemplos de iniciativas en este ámbito incluyen:

* **IA para salud pública:** sistemas de IA que analizan brotes epidémicos o facilitan diagnósticos en zonas rurales.
* **IA para energía y medio ambiente:** algoritmos que optimizan el consumo energético en ciudades o redes eléctricas inteligentes.
* **Educación inclusiva:** adaptadores automáticos de contenido educativo para personas con discapacidad (visión o audición).
* **Agricultura sostenible:** sistemas predictivos que ayudan a agricultores a optimizar uso del agua y fertilizantes.
* **Políticas públicas basadas en datos:** uso de IA para monitorizar progreso de los Objetivos de Desarrollo Sostenible (ODS), mejorando la eficiencia de programas sociales.

**Recursos recomendados:** Se recomiendan lecturas sobre principios éticos (p.ej. las líneas guía de la UNESCO o de la OCDE sobre IA), así como informes de iniciativas “AI for Good” (ONU). Cursos en línea sobre IA responsable (por ejemplo, “Ethics of AI” de edX) y seminarios sobre sostenibilidad en tecnología son útiles. También conviene familiarizarse con herramientas de auditoría de modelos (por ejemplo, paquetes de Python para medir sesgos) y seguir portales como AI4Good o la Cátedra UNESCO en IA. La bibliografía puede incluir textos de ética de la tecnología y casos de estudio reales.

## Web Semántica y Enlazado de Datos (Semantic Web & Linked Data) <a id="web-semántica-y-enlazado-de-datos-semantic-web--linked-data"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** En esta asignatura se estudian los **conceptos de Web Semántica**, es decir, representar datos en la web de forma estructurada y vinculada. Se trabajan los lenguajes y estándares (RDF, OWL, SPARQL) que permiten describir entidades y relaciones de modo que las máquinas puedan “comprender” el significado de la información. También se abordan técnicas de **Linked Data** y gráficas de conocimiento (knowledge graphs). El alumno aprende a construir ontologías, poblar bases de triples de datos y formular consultas complejas en SPARQL. Se discute cómo enlazar datos abiertos (Open Data) de distintas fuentes para formar conjuntos integrados de conocimiento.

**Valor académico/profesional:** La Web Semántica es clave para organizar la información en dominios avanzados (biomedicina, finanzas, gobierno electrónico). Permite un análisis de datos más sofisticado y la interoperabilidad entre sistemas. Por ejemplo, muchos buscadores (Google Knowledge Graph) y proyectos de datos públicos usan estos estándares para mejorar la búsqueda y la integración de información. Aprender estos métodos capacita para trabajar con **grandes grafos de conocimiento**, que cada vez son más usados en industria (p. ej. gestión de inventarios conectados en la logística). A nivel académico, prepara para investigar en campos como recuperación semántica de información, agentes inteligentes en web de datos o sistemas de razonamiento sobre grafos.

**Aplicaciones prácticas:** Entre sus aplicaciones destacan:

* **Gestión de datos abiertos:** vincular catálogos de bibliotecas, bases de datos de organismos públicos o científicos para crear redes de información enlazadas accesibles.
* **Recomendación semántica:** servicios que utilizan grafos de conocimiento (por ejemplo, DBpedia, Wikidata) para sugerir contenidos relacionados basados en significado, no solo en palabras clave.
* **Asistentes virtuales:** integración de conocimiento semántico para mejorar respuestas a preguntas complejas (por ejemplo, infobots que comprenden conceptos).
* **Industria 4.0:** modelos de conocimiento que unifican información de sensores y procesos en fábricas inteligentes, facilitando análisis y mantenimiento predictivo.

**Recursos recomendados:** Es esencial practicar con herramientas como **Protégé** (entorno gráfico para ontologías OWL), bases de datos triple store (por ejemplo **Apache Jena Fuseki**, **GraphDB**) y formular consultas SPARQL. Como bibliografía, *“Linked Data: Evolving the Web into a Global Data Space”* de Tom Heath & Christian Bizer es una referencia. También conviene explorar repositorios de Linked Open Data (p.ej. el portal Datahub) y tutoriales sobre construcción de Knowledge Graphs. La práctica con proyectos de vocabularios estandarizados (Schema.org, FOAF, etc.) ayuda a entender los retos de interoperabilidad.

## Métodos de Aprendizaje Automático (Machine Learning) <a id="métodos-de-aprendizaje-automático-machine-learning"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** Esta asignatura introduce las **técnicas más importantes del aprendizaje automático**. Cubre los tres paradigmas principales: aprendizaje supervisado (clasificación, regresión), no supervisado (clustering, reducción de dimensionalidad) y por refuerzo. El objetivo es que el alumno comprenda el marco general en el que encajar cada técnica y pueda elegir la más adecuada para un problema determinado. Se estudian algoritmos clásicos (árboles de decisión, SVM, k-means, redes neuronales) y la forma de evaluarlos (validación cruzada, métricas). La asignatura complementa otras materias del máster explicando el contexto y la selección de métodos (en lugar de su implementación de cero).

**Valor académico/profesional:** El aprendizaje automático es la base de la mayoría de soluciones de IA actuales. Conocer sus métodos y contexto es indispensable en investigación e industria. Los conocimientos adquiridos sirven para áreas tan variadas como análisis de datos, detección de anomalías, sistemas de recomendación o automatización inteligente. Por ejemplo, en e-commerce se utilizan algoritmos de clasificación y clustering para predecir compras o segmentar usuarios; en la industria manufacturera se aplican técnicas supervisadas para mantenimiento predictivo; en finanzas, para detectar riesgos crediticios o fraudes; e incluso en producción automotriz (sensores de vehículos) y en cualquier campo donde “la máquina aprenda de los datos”. La asignatura da la visión global necesaria antes de estudiar cada técnica en detalle.

**Aplicaciones prácticas:** Ejemplos de usos son:

* **Predicción y clasificación:** desde predecir precios inmobiliarios con regresión, hasta clasificar imágenes o correos electrónicos como spam.
* **Agrupamiento de datos:** análisis de comportamiento de clientes agrupándolos según características similares (clustering) para estrategias de marketing.
* **Recomendadores:** algoritmos que aprenden de preferencias de usuarios para sugerir productos, películas o contenidos.
* **Sistemas adaptativos:** como parte de sistemas de IA que se autoajustan con el tiempo (por ejemplo, ajustes en detección de fallos).

**Recursos recomendados:** Se recomienda usar **Scikit-Learn** en Python para implementar los algoritmos estudiados. Libros clásicos incluyen *“Pattern Recognition and Machine Learning”* de Christopher Bishop o *“Machine Learning”* de Alpaydın. Cursos gratuitos (por ejemplo, el famoso curso de Andrew Ng “Machine Learning” en Coursera) son muy útiles para afianzar conceptos. También existen repositorios de prácticas (como el repositorio de ejemplos de Scikit-Learn) y competiciones en Kaggle donde el alumno puede aplicar estos métodos a datos reales. Además, seguir blogs y tutoriales actualizados ayuda a entender las tendencias recientes (aprendizaje por refuerzo, aprendizaje activo, etc.).

## Trabajo de Fin de Máster en Investigación en IA <a id="trabajo-de-fin-de-máster-en-investigación-en-ia"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** El Trabajo Fin de Máster (TFM) constituye una asignatura de investigación donde el alumno debe realizar un proyecto original de 27 créditos (675 horas de trabajo) en el ámbito de la inteligencia artificial. Implica **identificar un problema no resuelto**, plantear objetivos científicos, implementar una solución utilizando técnicas de IA y evaluar los resultados siguiendo el método científico. El TFM debe contribuir al estado del arte: idealmente, culminar con resultados susceptibles de ser publicados en congresos o revistas indexadas. El proceso incluye revisión bibliográfica, definición de metodología, programación de algoritmos y análisis de experimentos bajo la supervisión de un director asignado.

**Valor académico/profesional:** El TFM es la culminación del máster y tiene como fin formar al alumno como futuro investigador. Desarrolla competencias críticas en investigación científica: formulación de hipótesis, diseño experimental y comunicación de resultados. Permite especializarse en un área concreta de IA a elección propia. Profesionalmente, trabajar en un proyecto de investigación dota de experiencia para roles en I+D de empresas o para continuar estudios de doctorado. Es la primera muestra de capacidad del estudiante para generar conocimiento original en el campo de la IA.

**Aplicaciones prácticas:** El TFM en sí es el desarrollo de una aplicación o estudio concreto en IA. Las aplicaciones dependen del tema escogido; pueden ir desde sistemas de visión, nuevos algoritmos de aprendizaje, herramientas de PLN, hasta marcos teóricos o análisis éticos. El resultado puede materializarse en un prototipo de software, un análisis de datos con hallazgos nuevos o incluso un simulador. En cualquier caso, el objetivo es que el trabajo tenga relevancia real (idealmente publicable) dentro del ámbito elegido.

**Recursos recomendados:** Para realizar el TFM se sugiere apoyarse en **publicaciones científicas** recientes (accediendo a repositorios como arXiv, IEEE o JCR) para fundamentar el estado del arte. Herramientas de gestión bibliográfica (Zotero, Mendeley) y de escritura académica (LaTeX, Git/GitHub para control de versiones) facilitan el trabajo. Es útil consultar las guías y FAQs oficiales del máster sobre criterios de admisión y supervisión. Además, se recomienda realizar prototipos con las mismas herramientas vistas en las asignaturas optativas (por ejemplo, entornos de aprendizaje automático o PLN) e iterar con feedback del director. La lectura del apartado “Metodología de investigación” previa (asignatura obligatoria) prepara al alumno en cómo plantear el proyecto.

## Metodología de Investigación en Sistemas Inteligentes <a id="metodología-de-investigación-en-sistemas-inteligentes"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

**Descripción:** Esta asignatura introduce la **metodología de investigación aplicada a la IA**. Cubre las etapas del método científico: planteamiento de hipótesis, diseño de experimentos, recolección y análisis de datos, redacción de resultados y referencias académicas. Sirve de preparación para las demás asignaturas optativas y, en especial, para el desarrollo del TFM. Se discuten criterios de publicación en conferencias, técnicas de revisión bibliográfica, aspectos éticos de la investigación y elaboración de propuestas de proyecto. Es de 3 créditos y se imparte en el primer semestre.

**Valor académico/profesional:** Dota al estudiante de las herramientas metodológicas esenciales para cualquier trabajo de investigación. El conocimiento adquirido facilita que el alumno pueda abordar con rigor científico problemas complejos, algo muy valorado en entornos académicos y en áreas de R\&D industrial. Saber plantear hipótesis de manera correcta y documentar resultados es una competencia clave que se usa también en desarrollo tecnológico profesional.

**Aplicaciones prácticas:** Aunque la asignatura no produce una aplicación técnica directa, sus conceptos se aplican en la realización de proyectos de investigación o desarrollo. Por ejemplo:

* **Literatura y estado del arte:** definir correctamente el marco teórico y citación de fuentes según norma.
* **Diseño experimental:** planificar experimentos con IA (p.ej. definir conjuntos de datos, métricas de evaluación) garantizando validez estadística.
* **Gestión de proyectos de IA:** aplicar principios de investigación a proyectos reales, identificando claramente los objetivos y métodos.

**Recursos recomendados:** Es conveniente revisar guías de trabajo científico como los estándares de la ACM/IEEE para redacción, así como leer artículos de conferencias de IA para entender estructura y estilo. Cursos en línea sobre *métodos de investigación* o *estadística aplicada* (por ejemplo, estadística para machine learning) apoyan la teoría. Herramientas útiles incluyen gestores bibliográficos (Zotero, EndNote), software estadístico (R, Python) para análisis y la plataforma Overleaf (LaTeX) para escribir textos académicos. También se recomienda revisar la **Guía del Estudiante del Máster**, donde se detallan requisitos y orientación del proceso de investigación.

**Fuentes:** Información tomada de las guías oficiales de las asignaturas en la UNED, así como de fuentes especializadas que describen aplicaciones actuales de estas tecnologías. Los recursos recomendados son ampliamente reconocidos en la literatura y la formación en IA (cursos de plataformas MOOC, libros de texto estándar y bibliotecas de código abierto).


## Autor <a id="autor"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

<div align="center" style="display: flex; align-items: center; justify-content: center; gap: 10px;">
  <a href="https://www.linkedin.com/in/fernando-mart%C3%ADnez-marco-a8127328/" target="_blank" style="display: flex; align-items: center;">
    <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/linkedin.svg" alt="LinkedIn" width="30" height="30" style="filter: invert(1);">
  </a>
  <a href="https://github.com/fmmarco29" target="_blank" style="display: flex; align-items: center;">
    <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/github.svg" alt="GitHub" width="30" height="30" style="filter: invert(1);">
  </a>
  <a href="https://fmmarco29.github.io/AI/" target="_blank" style="display: flex; align-items: center;">
    <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/githubpages.svg" alt="GitHub Pages" width="80" height="80" style="filter: invert(1);">
  </a>
  <a href="https://huggingface.co/fmcsihe2929" target="_blank" style="display: flex; align-items: center;">
    <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/huggingface.svg" alt="Hugging Face" width="30" height="30" style="filter: invert(1);">
  </a>
  <a href="mailto:fmmarco29@outlook.com" target="_blank" style="display: flex; align-items: center;">
    <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/microsoftoutlook.svg" alt="Outlook" width="30" height="30" style="filter: invert(1);">
  </a>
</div>

<div align="center" style="font-size: 60%; margin-top: 0.2rem;">
  © 2025 Fernando Martínez Marco
</div>


## Licencia <a id="licencia"></a> [↑ Volver al inicio](#uned-master-en-investigación-en-inteligencia-artificial)

Este proyecto está licenciado bajo la Licencia MIT. Ver [LICENSE](LICENSE) para más detalles.

---

<div align="center">

**¡No olvides dar una estrella si te ha sido útil!**

</div>